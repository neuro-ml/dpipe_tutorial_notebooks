{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with patches\n",
    "\n",
    "If your pipeline requires images of a given shape, you may want to split larger images into patches, perform some operations and then combine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.bluecross.org.uk/sites/default/files/d8/assets/images/118809lprLR.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "image = imread('118809lprLR.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "model = resnet50(pretrained=True)\n",
    "# resnet requires normalization\n",
    "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll classify this image by averaging the logits on each patch. We'll be taking patches in a convolution-like fashion, i.e. with a fixed stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpipe.medim import grid\n",
    "from dpipe.torch import to_var, to_np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpipe.medim.shape_utils import shape_after_convolution\n",
    "\n",
    "x = np.moveaxis(image.astype('float32'), -1, 0) # move channels forward\n",
    "x = x / 256\n",
    "\n",
    "probas = []\n",
    "for patch in grid.divide(x, patch_size=(256, 256), stride=32, valid=True):\n",
    "    # move the patch to the same device as the model\n",
    "    patch = to_var(patch, device=model)\n",
    "    patch = normalize(patch)\n",
    "    pred = to_np(model(patch[None])[0])\n",
    "    pred = softmax(pred)\n",
    "    \n",
    "    # according to https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a\n",
    "    # 281 is \"tabby, tabby cat\"\n",
    "    probas.append(pred[281][None, None])\n",
    "\n",
    "output_shape = shape_after_convolution(x.shape[1:], kernel_size=256, stride=32)\n",
    "# combine \"patches\" of shape (1, 1) into an image of `output_shape` with stride 1\n",
    "heatmap = grid.combine(probas, output_shape, stride=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(heatmap)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patches segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn_resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.moveaxis(image.astype('float32'), -1, 0) # move channels forward\n",
    "x = x / 256\n",
    "\n",
    "probas = []\n",
    "for patch in grid.divide(x, patch_size=(256, 256), stride=32):\n",
    "    # move the patch to the same device as the model\n",
    "    patch = to_var(patch, device=model)\n",
    "    patch = normalize(patch)\n",
    "    \n",
    "    pred = model(patch[None])['out'][0]\n",
    "    pred = to_np(pred)\n",
    "    # 'cat' is 8\n",
    "    pred = pred[8]\n",
    "    \n",
    "    probas.append(pred)\n",
    "\n",
    "segmentation = grid.combine(probas, x.shape[1:], stride=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(segmentation)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using predictors\n",
    "\n",
    "The previous approach is a quite common pattern: split -> segment -> combine, that's why there is a predictor that reduces boilerplate code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpipe.predict import patches_grid\n",
    "\n",
    "\n",
    "@patches_grid(patch_size=(256, 256), stride=(32, 32), padding_values=None)\n",
    "def segment(patch):\n",
    "    patch = to_var(patch, device=model)\n",
    "    patch = normalize(patch)\n",
    "    \n",
    "    pred = model(patch[None])['out'][0]\n",
    "    # 'cat' is 8\n",
    "    return to_np(pred[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then reuse this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = segment(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Miniconda3",
   "language": "python",
   "name": "miniconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
