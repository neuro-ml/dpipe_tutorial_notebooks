{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predict\n",
    "\n",
    "\n",
    "Usually when dealing with neural networks, at inference time the input\n",
    "data may require some preprocessing before being fed into the network.\n",
    "Also, the network’s output might need postprocessing in order to obtain\n",
    "a final prediction.\n",
    "\n",
    "### Padding and cropping\n",
    "\n",
    "Let’s suppose that we have a ``network`` for segmentation that can only\n",
    "work with images larger than 256x256 pixels.\n",
    "\n",
    "Before feeding a given `image` into the network you may want to pad it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dpipe.medim.shape_ops import pad_to_shape\n",
    "\n",
    "padded = pad_to_shape(image, np.maximum(image.shape, (256, 256)))\n",
    "mask = network(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Now you need to remove the padding in order to make the ``mask`` of same\n",
    "shape as ``image``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dpipe.medim.shape_ops import crop_to_shape\n",
    "\n",
    "mask = crop_to_shape(mask, image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Let’s make a function that implements the whole pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dpipe.medim.shape_ops import pad_to_shape, crop_to_shape\n",
    "\n",
    "def predict_pad(image, network, min_shape):\n",
    "    # pad\n",
    "    padded = pad_to_shape(image, np.maximum(image.shape, min_shape))\n",
    "    # predict\n",
    "    mask = network(padded)\n",
    "    # restore\n",
    "    mask = crop_to_shape(mask, image.shape)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Now we have a perfectly reusable function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Scale\n",
    "\n",
    "Now let's write a function that downsamples the input by a factor of 2 and then zooms the output by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dpipe.medim.shape_ops import zoom, zoom_to_shape\n",
    "\n",
    "def predict_zoom(image, network, scale_factor=0.5):\n",
    "    # zoom\n",
    "    zoomed = zoom(image, scale_factor)\n",
    "    # predict\n",
    "    mask = network(zoomed)\n",
    "    # restore\n",
    "    mask = zoom_to_shape(mask, image.shape)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Combining\n",
    "\n",
    "Now suppose we want to combine zooming and padding. We could do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dpipe.medim.shape_ops import pad_to_shape, crop_to_shape\n",
    "\n",
    "def predict(image, network, min_shape, scale_factor):\n",
    "    # zoom\n",
    "    zoomed = zoom(image, scale_factor)\n",
    "    \n",
    "    # ---\n",
    "    # pad\n",
    "    padded = pad_to_shape(image, np.maximum(zoomed.shape, min_shape))\n",
    "    # predict\n",
    "    mask = network(padded)\n",
    "    # restore\n",
    "    mask = crop_to_shape(mask, np.minimum(mask.shape, zoomed.shape))\n",
    "    # ---\n",
    "    \n",
    "    mask = zoom_to_shape(mask, image.shape)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Note how the content of `predict` is divided in two regions: basically it looks like the function `predict_zoom` but with the line \n",
    "```\n",
    "mask = network(padded)\n",
    "```\n",
    "replaced by the body of `predict_pad`.\n",
    "\n",
    "Basically, it means that we can pass `predict_pad` as the `network` argument and reuse the functions we defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def predict(image, network, min_shape, scale_factor):\n",
    "    def network_(x):\n",
    "        return predict_pad(x, network, min_shape)\n",
    "    \n",
    "    return predict_zoom(image, network_, scale_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "`predict_pad` \"wraps\" the original `network` - it behaves like `network`, and `predict_zoom` doesn't really care whether it received the original `network` or a wrapped one.\n",
    "\n",
    "This sounds just like a decorator (a very good explanation can be found [here](https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators/1594484#1594484)).\n",
    "\n",
    "If we implement `predict_pad` and `predict_zoom` as decorators we can more easily reuse them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def predict_pad(min_shape):\n",
    "    def decorator(network):\n",
    "        def predict(image):\n",
    "            # pad\n",
    "            padded = pad_to_shape(image, np.maximum(image.shape, min_shape))\n",
    "            # predict\n",
    "            mask = network(padded)\n",
    "            # restore\n",
    "            mask = crop_to_shape(mask, np.minimum(mask.shape, image.shape))\n",
    "            return mask\n",
    "        \n",
    "        return predict\n",
    "    return decorator\n",
    "\n",
    "def predict_zoom(scale_factor):\n",
    "    def decorator(network):\n",
    "        def predict(image):\n",
    "            # zoom\n",
    "            zoomed = zoom(image, scale_factor)\n",
    "            # predict\n",
    "            mask = network(padded)\n",
    "            # restore\n",
    "            mask = zoom_to_shape(mask, image.shape)\n",
    "            return mask\n",
    "\n",
    "        return predict\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Then the same `predict` can be defined like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "@predict_zoom(0.5)\n",
    "@predict_pad((256, 256))\n",
    "def predict(image):\n",
    "    # here the image is already zoomed and padded\n",
    "    return network(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Now `predict` is just a function that receives a single argument - the image.\n",
    "\n",
    "If you don't like the decorator approach you can use a handy function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from dpipe.predict.functional import chain_decorators\n",
    "\n",
    "predict = chain_decorators(\n",
    "    predict_zoom(0.5), \n",
    "    predict_pad((256, 256)),\n",
    "    predict=network,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "which gives the same function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
